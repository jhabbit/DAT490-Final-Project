{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f37de914",
      "metadata": {
        "id": "f37de914"
      },
      "source": [
        "# Modeling (GARCH, VAR/Granger/IRFs, Wavelets)\n",
        "This notebook fits GARCH(1,1) per asset, a VAR model for BTC↔S&P spillovers, and a discrete wavelet transform (DWT) for scale analysis.\n",
        "\n",
        "**Outputs saved:**\n",
        "- `figures/*_garch_sigma.png`\n",
        "- `tables/garch_params.csv`\n",
        "- `figures/var_impulse_responses.png`, `tables/var_summary.txt`\n",
        "- `figures/wavelet_energy.png`, `tables/wavelet_energy.csv`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66e0c6bb",
      "metadata": {
        "id": "66e0c6bb"
      },
      "outputs": [],
      "source": [
        "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "BASE = \"/content\" if os.path.exists(\"/content\") else \".\"\n",
        "DATA = f\"{BASE}/data\"\n",
        "FIG  = f\"{BASE}/figures\"; os.makedirs(FIG, exist_ok=True)\n",
        "TAB  = f\"{BASE}/tables\";  os.makedirs(TAB, exist_ok=True)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
        "print(\"BASE:\", BASE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba96d7a5",
      "metadata": {
        "id": "ba96d7a5"
      },
      "source": [
        "> If running in a fresh Colab, install deps using `requirements.txt`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7a5a91b",
      "metadata": {
        "id": "b7a5a91b"
      },
      "outputs": [],
      "source": [
        "!pip -q install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e1b3ea3",
      "metadata": {
        "id": "6e1b3ea3"
      },
      "source": [
        "## Load returns\n",
        "Prefer `data/returns_daily.csv` (from Stooq). If missing, build returns from `data/merged_returns.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c610e18",
      "metadata": {
        "id": "8c610e18"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, numpy as np, os\n",
        "\n",
        "rets_path = f\"{DATA}/returns_daily.csv\"\n",
        "merged_path = f\"{DATA}/merged_returns.csv\"\n",
        "\n",
        "if os.path.exists(rets_path):\n",
        "    rets = pd.read_csv(rets_path, parse_dates=[\"Date\"]).set_index(\"Date\").sort_index()\n",
        "    print(\"Loaded daily returns from\", rets_path, rets.shape)\n",
        "else:\n",
        "    if not os.path.exists(merged_path):\n",
        "        raise FileNotFoundError(\"Neither data/returns_daily.csv nor data/merged_returns.csv found.\")\n",
        "    df = pd.read_csv(merged_path, parse_dates=[\"Date\"]).set_index(\"Date\").sort_index()\n",
        "    BTC_CLOSE = \"BTC_Close\"\n",
        "    ETH_CLOSE = \"ETH_Close\" if \"ETH_Close\" in df.columns else None\n",
        "    SPX_RET   = \"SPX_Close_Return\"\n",
        "    DJI_CLOSE = \"DJI_Close\" if \"DJI_Close\" in df.columns else None\n",
        "    cols = {}\n",
        "    if \"BTC_Close_Return\" in df.columns:\n",
        "        cols[\"BTC-USD\"] = df[\"BTC_Close_Return\"]\n",
        "    else:\n",
        "        if BTC_CLOSE not in df.columns:\n",
        "            raise KeyError(\"BTC_Close_Return missing and BTC_Close not present to compute it.\")\n",
        "        cols[\"BTC-USD\"] = np.log(df[BTC_CLOSE]).diff()*100\n",
        "    if ETH_CLOSE and (\"ETH_Close_Return\" in df.columns):\n",
        "        cols[\"ETH-USD\"] = df[\"ETH_Close_Return\"]\n",
        "    elif ETH_CLOSE:\n",
        "        cols[\"ETH-USD\"] = np.log(df[ETH_CLOSE]).diff()*100\n",
        "    if SPX_RET in df.columns:\n",
        "        cols[\"^GSPC\"] = df[SPX_RET]\n",
        "    else:\n",
        "        if \"SPX_Close\" in df.columns:\n",
        "            cols[\"^GSPC\"] = np.log(df[\"SPX_Close\"]).diff()*100\n",
        "    if \"DJI_Close_Return\" in df.columns:\n",
        "        cols[\"^DJI\"] = df[\"DJI_Close_Return\"]\n",
        "    elif DJI_CLOSE:\n",
        "        cols[\"^DJI\"] = np.log(df[DJI_CLOSE]).diff()*100\n",
        "\n",
        "    rets = pd.DataFrame(cols).dropna(how=\"all\").dropna()\n",
        "    print(\"Built returns from merged file:\", merged_path, rets.shape)\n",
        "\n",
        "display(rets.tail())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df1722fd",
      "metadata": {
        "id": "df1722fd"
      },
      "source": [
        "## GARCH(1,1) per asset\n",
        "Fits a standard GARCH(1,1) with Gaussian errors; exports parameter table and conditional volatility plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a16b50e1",
      "metadata": {
        "id": "a16b50e1"
      },
      "outputs": [],
      "source": [
        "from arch import arch_model\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "\n",
        "targets = [c for c in rets.columns if c in [\"BTC-USD\",\"ETH-USD\",\"^GSPC\",\"^DJI\"]]\n",
        "if not targets:\n",
        "    targets = list(rets.columns)[:4]\n",
        "\n",
        "rows = []\n",
        "for col in targets:\n",
        "    series = rets[col].dropna()\n",
        "    am = arch_model(series, vol=\"GARCH\", p=1, q=1, mean=\"Constant\", dist=\"normal\")\n",
        "    res = am.fit(disp=\"off\")\n",
        "    params = res.params\n",
        "    alpha = params.get(\"alpha[1]\", np.nan)\n",
        "    beta  = params.get(\"beta[1]\" , np.nan)\n",
        "    rows.append({\n",
        "        \"asset\": col,\n",
        "        \"mu\": params.get(\"mu\", np.nan),\n",
        "        \"omega\": params.get(\"omega\", np.nan),\n",
        "        \"alpha\": alpha,\n",
        "        \"beta\": beta,\n",
        "        \"alpha_plus_beta\": (alpha + beta) if np.isfinite(alpha) and np.isfinite(beta) else np.nan,\n",
        "        \"llf\": res.loglikelihood,\n",
        "        \"ljungbox_p(10)\": acorr_ljungbox(res.std_resid.dropna(), lags=[10], return_df=True)[\"lb_pvalue\"].values[0]\n",
        "    })\n",
        "    res.conditional_volatility.plot()\n",
        "    plt.title(f\"GARCH(1,1) Conditional Volatility — {col}\")\n",
        "    plt.xlabel(\"Date\"); plt.ylabel(\"Volatility (σ_t)\")\n",
        "    out = f\"{FIG}/{col.replace('^','')}_garch_sigma.png\"\n",
        "    plt.tight_layout(); plt.savefig(out, dpi=150); plt.close()\n",
        "    print(\"Saved:\", out)\n",
        "\n",
        "garch_tbl = pd.DataFrame(rows)\n",
        "garch_tbl.to_csv(f\"{TAB}/garch_params.csv\", index=False)\n",
        "display(garch_tbl)\n",
        "print(\"Saved table:\", f\"{TAB}/garch_params.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6b42c45",
      "metadata": {
        "id": "c6b42c45"
      },
      "source": [
        "## VAR(p) with AIC lag selection, Granger causality, IRFs\n",
        "We focus on BTC and S&P 500 to quantify short-horizon spillovers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8d77fb5",
      "metadata": {
        "id": "f8d77fb5"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.api import VAR\n",
        "\n",
        "need = [c for c in [\"BTC-USD\",\"^GSPC\"] if c in rets.columns]\n",
        "if len(need) < 2:\n",
        "    need = list(rets.columns[:2])\n",
        "    print(\"Using first two columns for VAR:\", need)\n",
        "\n",
        "Y = rets[need].dropna()\n",
        "model = VAR(Y)\n",
        "res = model.fit(ic=\"aic\", trend=\"c\")\n",
        "lag = res.k_ar\n",
        "print(\"AIC-selected lag:\", lag)\n",
        "\n",
        "with open(f\"{TAB}/var_summary.txt\",\"w\") as f:\n",
        "    f.write(str(res.summary()))\n",
        "    try:\n",
        "        f.write(\"\n",
        "\n",
        "Granger ({} <- {}):\n",
        "\".format(need[0], need[1]))\n",
        "        f.write(str(res.test_causality(need[0], [need[1]], kind=\"f\").summary()))\n",
        "    except Exception as e:\n",
        "        f.write(f\"\n",
        "\n",
        "Granger test 1 failed: {e}\")\n",
        "    try:\n",
        "        f.write(\"\n",
        "\n",
        "Granger ({} <- {}):\n",
        "\".format(need[1], need[0]))\n",
        "        f.write(str(res.test_causality(need[1], [need[0]], kind=\"f\").summary()))\n",
        "    except Exception as e:\n",
        "        f.write(f\"\n",
        "\n",
        "Granger test 2 failed: {e}\")\n",
        "print(\"Saved:\", f\"{TAB}/var_summary.txt\")\n",
        "\n",
        "irf = res.irf(10)\n",
        "fig = irf.plot(orth=False)\n",
        "out = f\"{FIG}/var_impulse_responses.png\"\n",
        "fig.savefig(out, dpi=150); plt.close(fig)\n",
        "print(\"Saved:\", out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05df13f5",
      "metadata": {
        "id": "05df13f5"
      },
      "source": [
        "## Wavelet decomposition (db4, level=3)\n",
        "Decompose BTC returns and plot energy distribution across components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eb7d6c5",
      "metadata": {
        "id": "8eb7d6c5"
      },
      "outputs": [],
      "source": [
        "import pywt\n",
        "\n",
        "series_name = \"BTC-USD\" if \"BTC-USD\" in rets.columns else rets.columns[0]\n",
        "series = rets[series_name].dropna().values\n",
        "wave, level = \"db4\", 3\n",
        "\n",
        "coeffs = pywt.wavedec(series, wavelet=wave, level=level)\n",
        "energies = [float(np.sum(c**2)) for c in coeffs]\n",
        "labels = [f\"A{level}\"] + [f\"D{j}\" for j in range(level, 0, -1)]\n",
        "\n",
        "plt.bar(labels, energies)\n",
        "plt.title(f\"Wavelet Energy — {series_name} ({wave}, level={level})\")\n",
        "plt.xlabel(\"Component\"); plt.ylabel(\"Energy\")\n",
        "out = f\"{FIG}/wavelet_energy.png\"\n",
        "plt.tight_layout(); plt.savefig(out, dpi=150); plt.close()\n",
        "print(\"Saved:\", out)\n",
        "\n",
        "pd.DataFrame({\"component\": labels, \"energy\": energies}).to_csv(f\"{TAB}/wavelet_energy.csv\", index=False)\n",
        "print(\"Saved:\", f\"{TAB}/wavelet_energy.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}